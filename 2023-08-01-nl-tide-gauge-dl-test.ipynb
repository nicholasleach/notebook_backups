{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29148d2-b6d1-459c-9635-557ad7ee48ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f931af-379c-4e72-9fab-b21716bb96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/home/nick/C2S-Python-API\")\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31921280-cbf5-4eb6-8810-d33764e0212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import noaa_coops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbd7dad-6269-4ff8-b89e-d8ce699dc896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample bbox from a geojson\n",
    "bbox = [[\n",
    "    [\n",
    "      -75.01920876517276,\n",
    "      36.528583600142895\n",
    "    ],\n",
    "    [\n",
    "      -80.17839668640761,\n",
    "      36.528583600142895\n",
    "    ],\n",
    "    [\n",
    "      -80.17839668640761,\n",
    "      32.4610893038282\n",
    "    ],\n",
    "    [\n",
    "      -75.01920876517276,\n",
    "      32.4610893038282\n",
    "    ],\n",
    "    [\n",
    "      -75.01920876517276,\n",
    "      36.528583600142895\n",
    "    ]\n",
    "  ]\n",
    "]\n",
    "bbox = bbox[0]\n",
    "bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e86ee-69d4-4469-bcb4-41ebe70d6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = min([x[1] for x in bbox]), max([x[1] for x in bbox])\n",
    "lons = min([x[0] for x in bbox]), max([x[0] for x in bbox])\n",
    "\n",
    "stations = noaa_coops.get_stations_from_bbox(lat_coords=lats, lon_coords=lons)\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831feda-9e94-440b-9793-261f67d376d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_station = noaa_coops.Station(stations[0])\n",
    "test_station.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d37f3-278a-4a8c-9396-8a43b0f8b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_levels = test_station.get_data(\n",
    "    begin_date=\"20210101\",\n",
    "    end_date=\"20210201\",\n",
    "    product=\"water_level\",\n",
    "    datum=\"MLLW\",\n",
    "    units=\"metric\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10d56ba-e37d-4fbe-a987-190e14c8fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c676e61-ac2e-44c9-9a0c-c79b6d11e4d6",
   "metadata": {},
   "source": [
    "[Description of what the columns represent](https://api.tidesandcurrents.noaa.gov/api/prod/responseHelp.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a4d3a-6fbc-4e76-90e9-48f9f83fdf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water_levels.plot(y=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52824f6-ab5c-44f9-b914-f4da369fac92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_station.products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb44d7a-9638-4109-98fa-00cb98a66e6c",
   "metadata": {},
   "source": [
    "Full list of options for `\"product\"`:\n",
    "\n",
    "```\n",
    "[\n",
    "    \"water_level\",\n",
    "    \"hourly_height\",\n",
    "    \"high_low\",\n",
    "    \"daily_mean\",\n",
    "    \"monthly_mean\",\n",
    "    \"one_minute_water_level\",\n",
    "    \"predictions\",\n",
    "    \"datums\",\n",
    "    \"air_gap\",\n",
    "    \"air_temperature\",\n",
    "    \"water_temperature\",\n",
    "    \"wind\",\n",
    "    \"air_pressure\",\n",
    "    \"conductivity\",\n",
    "    \"visibility\",\n",
    "    \"humidity\",\n",
    "    \"salinity\",\n",
    "    \"currents\",\n",
    "    \"currents_predictions\",\n",
    "    \"ofs_water_level\",\n",
    "]\n",
    "```\n",
    "\n",
    "There may be some others available that are considered \"meteorlogical conditions\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d90b2e5-3230-4e5a-9f06-2707dda996eb",
   "metadata": {},
   "source": [
    "## Checking hourly levels for any NaNs or other strange values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2054cf2-b9f8-4cec-937b-057c12e46275",
   "metadata": {},
   "source": [
    "Look at the record for Sandy Hook (according to an [NYT article](https://www.nytimes.com/2014/01/14/science/tide-gauges-needed-for-research-are-often-victims-of-storms.html), it washed out during Hurricane Sandy on October 29, 2012).\n",
    "\n",
    "`An astonishing 73 tide stations were damaged or destroyed as Sandy swept across the North Atlantic basin, including ones in Puerto Rico and the United States Virgin Islands.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77276b-ae84-4cff-84ee-456dc54e176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = noaa_coops.Station(\"8531680\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e683a2-0fb8-481e-ac05-ce04b5048891",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(station.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c1d205-8075-4c88-9053-85a67eac405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Sandy Hook gauge during Hurricane Sandy\n",
    "df_hourly = station.get_data(\n",
    "    begin_date=\"20121028\",\n",
    "    end_date=\"20121030\",\n",
    "    product=\"hourly_height\",\n",
    "    datum=\"MLLW\",\n",
    "    units=\"metric\",\n",
    ")\n",
    "print(len(df_hourly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf4c11-6974-4864-82ec-169229d81520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a few more days and see if it's the same length\n",
    "df_hourly = station.get_data(\n",
    "    begin_date=\"20121028\",\n",
    "    end_date=\"20121105\",\n",
    "    product=\"hourly_height\",\n",
    "    datum=\"MLLW\",\n",
    "    units=\"metric\",\n",
    ")\n",
    "print(len(df_hourly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcbed74-5813-4b17-b4b7-6e3d1495b2d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af361a45-a092-4604-b85c-5f99e050226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the expected hours\n",
    "expected_hours = pd.date_range(\"2012-10-28\", \"2012-11-05\", freq=\"H\")\n",
    "print(len(expected_hours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a202f-cdc0-4f8d-b925-62f4a61e65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find missing hours\n",
    "[x for x in expected_hours if x not in df_hourly.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da8cf1-07a7-4ac9-8126-06ed915d1069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: get years of data for a gauge, check for missing data\n",
    "start_date = \"2010-01-01\"\n",
    "end_date = \"2020-01-01\"\n",
    "df_water_levels = test_station.get_data(\n",
    "    begin_date=start_date.replace(\"-\", \"\"),\n",
    "    end_date=end_date.replace(\"-\", \"\"),\n",
    "    product=\"hourly_height\",\n",
    "    datum=\"MSL\",\n",
    "    units=\"metric\",\n",
    ")\n",
    "\n",
    "expected_hours = pd.date_range(start_date, end_date, freq=\"H\")\n",
    "\n",
    "print(len(df_water_levels))\n",
    "print(len(expected_hours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23985a2f-f3b0-48b7-a39c-2b13b997d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the timeframe encompasses a no-data period, the no-data period is filled with NaNs\n",
    "# so either missing rows or NaNs indicate outages\n",
    "def search_for_outages(station_id, start_date, end_date, debug=False):\n",
    "    \"\"\"Return (bool, df) where bool is True if dates are missing\n",
    "    start_date and end_date in \"YYYY-mm-dd\" format.\n",
    "    \"\"\"\n",
    "    station = noaa_coops.Station(station_id)\n",
    "    df = station.get_data(\n",
    "        begin_date=start_date.replace(\"-\", \"\"),\n",
    "        end_date=end_date.replace(\"-\", \"\"),\n",
    "        product=\"hourly_height\",\n",
    "        datum=\"MSL\",\n",
    "        units=\"metric\",\n",
    "    )\n",
    "\n",
    "    # missing rows are one indication of outages\n",
    "    # but need to account for starting availability\n",
    "    record_start = station.data_inventory[\"Verified Hourly Height Water Level\"][\"start_date\"].split(\" \")[0]\n",
    "    record_end = station.data_inventory[\"Verified Hourly Height Water Level\"][\"end_date\"].split(\" \")[0]\n",
    "    expected_hours = pd.date_range(\n",
    "        max(start_date, record_start), min(end_date, record_end), freq=\"H\"\n",
    "    )\n",
    "    # if the record start/end date is different than submitted, print as an alert\n",
    "    if debug:\n",
    "        if (start_date != max(start_date, record_start)) or (end_date != min(end_date, record_end)):\n",
    "            print(f\"start: {max(start_date, record_start)}\")\n",
    "            print(f\"end:   {min(end_date, record_end)}\")\n",
    "    num_missing = len(expected_hours) - len(df)\n",
    "\n",
    "    # NaNs are another indication\n",
    "    nan_hours = np.sum(df[\"v\"].isna())\n",
    "    \n",
    "    # flags set to (1,1) are the last indication\n",
    "    flagged_hours = np.sum(df[\"f\"].apply(lambda x: x==\"1,1\"))\n",
    "    \n",
    "    if any(x > 0 for x in [nan_hours, flagged_hours]):\n",
    "        if debug:\n",
    "            print(f\"{nan_hours=}\")\n",
    "            print(f\"{flagged_hours=}\")\n",
    "        print(f\"{station_id} ({station.name}) is missing {nan_hours} hours.\")\n",
    "    else:\n",
    "        print(f\"{station_id} ({station.name}) has no missing hours.\")        \n",
    "\n",
    "    return nan_hours, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a305f2f-7d36-481c-bd4c-7b7030d97421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use on a known case (Sandy Hook, NJ during a period covering Hurricane Sandy)\n",
    "missing, df = search_for_outages(\"8531680\", \"2010-01-01\", \"2015-01-01\")\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7578088-44b3-4258-98cf-f54c6196c793",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(y=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede37350-3836-47d1-93b2-e206fff83eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some atlantic stations\n",
    "stations = [\n",
    "    '8651370',\n",
    "    '8652587',\n",
    "    '8654467',\n",
    "    '8656483',\n",
    "    '8658120',\n",
    "    '8658163',\n",
    "    '8661070',\n",
    "    '8665530'\n",
    "]\n",
    "\n",
    "missing_hours_counts = []\n",
    "dfs = {}\n",
    "for station_id in stations:\n",
    "    missing, df = search_for_outages(station_id, \"2000-01-01\", \"2020-01-01\")\n",
    "    missing_hours_counts.append(missing)\n",
    "    dfs[station_id] = df\n",
    "    print(\"#\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9639d-7e18-4160-b5ac-ad42c99eef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check on the Charleston station where there are 16 flagged hours but with apparently valid data\n",
    "df = dfs[\"8665530\"]\n",
    "df.loc[df[\"f\"] == \"1,1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1900ed94-7a85-4904-b9fa-9e7df7f10fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"2015-02-20\", :].plot(y=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5a76f-fae3-46f3-82b4-3688b97dfc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's going on with Springmaid Pier, where we see a massive outage?\n",
    "dfs[\"8661070\"].plot(y=\"v\")\n",
    "plt.show()\n",
    "dfs[\"8661070\"].loc[\"2000-11-30\":\"2000-12-31\", :].plot(y=\"v\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9bc49-a1e2-4c48-91ea-f6b625557dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's going on with Springmaid Pier, where we see a massive outage?\n",
    "missing, df = search_for_outages(\"8661070\", \"2000-01-01\", \"2020-01-01\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6b3f1-bd87-49c5-b63f-6acdcaeec35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"v\"].isna(), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f02c69e-008f-481c-abc6-e7aa3b3fd22b",
   "metadata": {},
   "source": [
    "## Checking results when querying for very long records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc6a92-b355-4d57-a888-12bfe398dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = noaa_coops.Station(\"8661070\")\n",
    "print(station.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4ce646-689e-4539-a3de-14742564fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "station.data_inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ffde1c-4187-4e49-b97c-f55934b7c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly water level starts in 1976. What happens if we query before then?\n",
    "out = station.get_data(\n",
    "    begin_date=\"19700101\",\n",
    "    end_date=\"20240101\",\n",
    "    product=\"hourly_height\",\n",
    "    datum=\"MSL\",\n",
    ")\n",
    "print(len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3883770c-53bb-464b-b54f-96e1f39a9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371071ce-dc19-46b6-8d1a-77e2077c33e3",
   "metadata": {},
   "source": [
    "## Merging dataframes with different lengths\n",
    "- Keep same index `t`\n",
    "- Keep v/s/f fields, but add an extra index indicating the station number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5876bb8-a3f0-4d9b-8a95-871391faf213",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfs[stations[0]]\n",
    "df2 = dfs[stations[2]]\n",
    "print(len(df1), len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc0cfe1-0be1-4c03-98cd-dd1903f4af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.concat([df1, df2], keys=[stations[0], stations[2]], axis=1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973176c-d51d-46f6-aeb5-6437ca4105d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[stations[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dac5b0-b049-4efb-a02d-579d5f90ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "merged_df[stations[0]].plot(ax=ax, y=\"v\", label=stations[0])\n",
    "merged_df[stations[2]].plot(ax=ax, y=\"v\", label=stations[2])\n",
    "ax.set_ylabel(\"gauge height (MSL)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e93854-605f-4ee6-933c-89199b10c89e",
   "metadata": {},
   "source": [
    "# Get full data record for all Atlantic stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9e704-1a74-46c6-b21f-0e33d3849379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can I use a nice geojson instead of just a bbox?\n",
    "# no. bbox it is, then.\n",
    "big_geom = [\n",
    "            [\n",
    "              -65.66547220355395,\n",
    "              47.26526924937144\n",
    "            ],\n",
    "            [\n",
    "              -70.50291308804213,\n",
    "              45.08503647353169\n",
    "            ],\n",
    "            [\n",
    "              -73.55751503025883,\n",
    "              43.23221741177247\n",
    "            ],\n",
    "            [\n",
    "              -78.62254525972577,\n",
    "              39.07613426999106\n",
    "            ],\n",
    "            [\n",
    "              -81.58254149491296,\n",
    "              34.24771068739118\n",
    "            ],\n",
    "            [\n",
    "              -82.91077131974842,\n",
    "              30.999542363635413\n",
    "            ],\n",
    "            [\n",
    "              -80.64070727870458,\n",
    "              25.998811021385663\n",
    "            ],\n",
    "            [\n",
    "              -80.4967240501288,\n",
    "              24.898305587208228\n",
    "            ],\n",
    "            [\n",
    "              -79.13777976049207,\n",
    "              26.50457433121548\n",
    "            ],\n",
    "            [\n",
    "              -78.6817855079541,\n",
    "              30.891384212027106\n",
    "            ],\n",
    "            [\n",
    "              -74.22090082631496,\n",
    "              35.331890706458864\n",
    "            ],\n",
    "            [\n",
    "              -73.21492407841056,\n",
    "              38.45502499546171\n",
    "            ],\n",
    "            [\n",
    "              -68.4983608573623,\n",
    "              41.254452775746785\n",
    "            ],\n",
    "            [\n",
    "              -66.52988282288521,\n",
    "              43.238472154019945\n",
    "            ],\n",
    "            [\n",
    "              -65.66547220355395,\n",
    "              47.26526924937144\n",
    "            ]\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23a8edf-b388-4159-8648-aa7d89572361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ids for all stations in this giant geometry\n",
    "lats = min([x[1] for x in big_geom]), max([x[1] for x in big_geom])\n",
    "lons = min([x[0] for x in big_geom]), max([x[0] for x in big_geom])\n",
    "\n",
    "stations = noaa_coops.get_stations_from_bbox(lat_coords=lats, lon_coords=lons)\n",
    "print(len(stations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235d5ca6-1a23-43c9-abee-52800857e578",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get records for all and merge into one big dataframe that we can save\n",
    "# search for any outages along the way\n",
    "missing_hours_counts = []\n",
    "dfs = {}\n",
    "for station_id in stations:\n",
    "    try:\n",
    "        missing, df = search_for_outages(station_id, \"1900-01-01\", \"2024-01-01\", debug=True)\n",
    "        missing_hours_counts.append(missing)\n",
    "        dfs[station_id] = df\n",
    "    except Exception as e:\n",
    "        print(f\"{station_id}: {e}\")\n",
    "    print(\"#\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee9941b-4568-453f-87ba-ec1990602e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a big dataframe and pickle it\n",
    "merged_df = pd.concat(list(dfs.values()), keys=list(dfs.keys()), axis=1)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a9771-5c00-41a5-a2ea-5b4afd3b09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle this massive guy\n",
    "merged_df.to_pickle(\"/data/surge/tide-gauge-hourly-records-eastcoast.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e708cd3-821c-4f55-9e9a-e0ccf45e0efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.memory_usage().sum() / 1e3 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de38c72-a82d-4055-b024-098f441e08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove flags\n",
    "idx = pd.IndexSlice\n",
    "merged_df = merged_df.loc[:, idx[:, [\"v\", \"s\"]]]\n",
    "# make sparse\n",
    "merged_df = merged_df.astype(pd.SparseDtype(\"float\", np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6d0bcf-f603-4380-860a-b7cd1fa6dd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.memory_usage().sum() / 1e3 / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe90400-6aac-4ead-a3e6-2d6b22d78169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle the sparse version\n",
    "merged_df.to_pickle(\"/data/surge/tide-gauge-hourly-records-eastcoast-sparse.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b454d3-2304-41cf-b18a-f6ae4c3d9f74",
   "metadata": {},
   "source": [
    "## How many gauges are completely continuous?\n",
    "Answer: none! but that may not be as bad as it seems; it doesn't mean this was always due to storms creating outages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9e3e6-47bd-4aab-a865-ac644157cf62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_hours_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05393525-0c62-4c87-b5cb-06ddcc89f8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"8656483\"].plot(y=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d67a7-3d62-4ab1-abec-f85cf156ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "noaa_coops.Station(\"8656483\").name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a274a8c7-a026-41ef-9b51-1919d514dbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of no-data since 2000?\n",
    "np.sum(dfs[\"8656483\"].loc[\"2000-01-01\":, \"v\"].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd645980-cb5b-4ae3-bbab-7b227de745f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about for a different gauge?\n",
    "np.sum(dfs[stations[2]].loc[\"2000-01-01\":, \"v\"].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e94c411-6453-47c6-aa6d-92c644e3fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(merged_df[stations[2]].loc[\"2000-01-01\":, \"v\"].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b592a4-a7e9-46b4-aae1-c4f98cf185ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[stations[2]].loc[\"2000-01-01\":, \"v\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58055f-10e2-4460-98aa-f99d20fc509b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[stations[2]].loc[\"2000-01-01\":, \"v\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b9d3c-19cf-4968-bacc-05ede8ba314e",
   "metadata": {},
   "source": [
    "## What is our average start date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316056e-90c8-4539-b411-569c8ac07953",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_pickle(\"/data/surge/tide-gauge-hourly-records-eastcoast-sparse.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b827021e-bc6a-4840-a947-f222998d278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915543ac-8035-4cb4-beab-25806cb583fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry\n",
    "def get_record_start(station_id):\n",
    "    return noaa_coops.Station(station_id).data_inventory[\"Verified Hourly Height Water Level\"][\"start_date\"].split(\" \")[0]\n",
    "\n",
    "def print_record_start(station_id):\n",
    "    print(get_record_start(station_id))\n",
    "\n",
    "record_start_dates = []\n",
    "for station_id in stations:\n",
    "    record_start_dates.append(get_record_start(station_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84726943-4c7c-4739-97bf-00b0f9ed9c77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "record_start_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673e3cdb-ebf2-4b0e-a20f-3b986f5613cf",
   "metadata": {},
   "source": [
    "## (jff) look at annual mean through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307ee0d-345f-4812-b5de-24ad960683f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "years = pd.date_range(\"1930-01-01\", \"2023-01-01\", freq=\"Y\")\n",
    "out = []\n",
    "for year in years:\n",
    "    out.append(np.nanmean(merged_df.loc[str(year.year), idx[:, \"v\"]]))\n",
    "\n",
    "plt.plot([year.year for year in years], out)\n",
    "plt.ylabel(\"MSL (national tidal datum) (m)\")\n",
    "plt.title(\"Annual average of NOAA tidal gauges\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7147e9c-52eb-4ac0-9aed-fdc17b881dd3",
   "metadata": {},
   "source": [
    "# Spatial properties of available tide gauges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60606e44-e062-48f2-96b7-ee7a37588a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_pickle(\"/data/surge/tide-gauge-hourly-records-eastcoast-sparse.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea751c-2fd9-409d-8382-27201a2889af",
   "metadata": {},
   "source": [
    "## Plot on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78bfcb-41db-46ea-8bf8-414c326553fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = [x[0] for x in merged_df.columns]\n",
    "stations_info = {}\n",
    "\n",
    "for station_id in stations:\n",
    "    station = noaa_coops.Station(station_id)\n",
    "    stations_info[station_id] = {}\n",
    "    stations_info[station_id][\"name\"] = station.name\n",
    "    stations_info[station_id][\"lat\"] = station.lat_lon[\"lat\"]\n",
    "    stations_info[station_id][\"lon\"] = station.lat_lon[\"lon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dac323-f3ed-44b6-a3ee-de2cd19f1526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(stations_info).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d27602-9119-4fd9-98b5-7fce591c5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, \"geometry\"] = df.apply(lambda x: shapely.geometry.Point(x[\"lon\"], x[\"lat\"]), axis=1)\n",
    "gdf = gpd.GeoDataFrame(df, geometry=\"geometry\", crs=4326)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377c453-a4b3-4997-901d-7dce8b54de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "ax.set_xlim(-85, -65)\n",
    "ax.set_ylim(25, 46)\n",
    "# put a simple coastline as a background\n",
    "borders.plot(ax=ax)\n",
    "# add tide gauges\n",
    "gdf.plot(color=\"red\", ax=ax, label=\"NOAA gauges\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a383cde4-2d27-4a8d-9357-9e52ac75c717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9f57c4e-af70-4f55-8562-302da158ecd2",
   "metadata": {},
   "source": [
    "## Use DB of US cities to see how many cities are near a tide gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff6bb0c-8278-4d4d-8a78-43b510f7fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = pd.read_csv(\"/data/static/uscities.csv\")\n",
    "cities.loc[:, \"geometry\"] = cities.apply(lambda x: shapely.geometry.Point(x[\"lng\"], x[\"lat\"]), axis=1)\n",
    "cities_gdf = gpd.GeoDataFrame(cities, geometry=\"geometry\", crs=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5c140-1db8-4496-b523-8b4755ebc813",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cities_gdf.loc[cities_gdf[\"population\"] > 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c23a7-6fcd-4acd-9e3e-4a04533659db",
   "metadata": {},
   "outputs": [],
   "source": [
    "borders = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "ax.set_xlim(-85, -65)\n",
    "ax.set_ylim(25, 46)\n",
    "# put a simple coastline as a background\n",
    "borders.plot(ax=ax)\n",
    "\n",
    "# add tide gauges\n",
    "gdf.plot(color=\"red\", ax=ax, label=\"NOAA gauges\")\n",
    "\n",
    "# add cities with a population over 100,000\n",
    "cities_gdf.loc[cities_gdf[\"population\"] > 100000].plot(color='yellow', ax=ax, label=\"cities w pop>100k\")\n",
    "\n",
    "# plot\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36070252-3578-40d8-b5fb-9fb6a4d5ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer tide gauges by 25km\n",
    "# USGS contiguous US albers equal area\n",
    "epsg = 5070\n",
    "\n",
    "\n",
    "borders = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "borders = borders.loc[borders[\"name\"].isin([\"Canada\", \"United States of America\"])]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "ax.set_xlim(1.25*1e6, 2.25*1e6)\n",
    "ax.set_ylim(0.25*1e6, 3.25*1e6)\n",
    "\n",
    "# put a simple coastline as a background\n",
    "borders.to_crs(epsg).plot(ax=ax, alpha=0.5)\n",
    "\n",
    "# add tide gauges\n",
    "gdf.to_crs(epsg).buffer(25000).plot(color=\"red\", ax=ax, label=\"NOAA gauges w 25km buffer\")\n",
    "\n",
    "# add cities with a population over 100,000\n",
    "cities_gdf.to_crs(epsg).loc[cities_gdf[\"population\"] > 100000].plot(color='yellow', ax=ax, label=\"cities w pop>100k\")\n",
    "\n",
    "# plot\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff985712-c269-40d1-bfcc-ac14634edd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some geometric \"isin\" operations\n",
    "pop_minimum = 100000\n",
    "\n",
    "\n",
    "# cities within 25km of a tide gauge\n",
    "out = cities_gdf[cities_gdf[\"population\"] > pop_minimum].to_crs(epsg)[\"geometry\"].within(gdf.to_crs(epsg).buffer(25000).unary_union)\n",
    "print(f\"Cities within 25km of a tide gauge: {np.sum(out)}\")\n",
    "\n",
    "# within 15km\n",
    "out = cities_gdf[cities_gdf[\"population\"] > pop_minimum].to_crs(epsg)[\"geometry\"].within(gdf.to_crs(epsg).buffer(15000).unary_union)\n",
    "print(f\"Cities within 15km of a tide gauge: {np.sum(out)}\")\n",
    "\n",
    "# 10km\n",
    "out = cities_gdf[cities_gdf[\"population\"] > pop_minimum].to_crs(epsg)[\"geometry\"].within(gdf.to_crs(epsg).buffer(10000).unary_union)\n",
    "print(f\"Cities within 10km of a tide gauge: {np.sum(out)}\")\n",
    "\n",
    "# 5km\n",
    "out = cities_gdf[cities_gdf[\"population\"] > pop_minimum].to_crs(epsg)[\"geometry\"].within(gdf.to_crs(epsg).buffer(5000).unary_union)\n",
    "print(f\"Cities within 5km of a tide gauge: {np.sum(out)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2779b3d-626f-4045-9c4c-725d543c430f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print names of cities with population greater than pop_minimum within 5km of a tide gauge\n",
    "cities_gdf.loc[out & (cities_gdf[\"population\"] > pop_minimum), [\"city\", \"state_id\"]].apply(lambda x: (x[\"city\"], x[\"state_id\"]), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c3049c-d5fc-4903-8505-457cd0766568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# buffer tide gauges by 25km\n",
    "# USGS contiguous US albers equal area\n",
    "epsg = 5070\n",
    "\n",
    "\n",
    "borders = gpd.read_file(gpd.datasets.get_path(\"naturalearth_lowres\"))\n",
    "borders = borders.loc[borders[\"name\"].isin([\"Canada\", \"United States of America\"])]\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "ax.set_xlim(0.50*1e6, 2.5*1e6)\n",
    "ax.set_ylim(0.25*1e6, 3.25*1e6)\n",
    "\n",
    "# put a simple coastline as a background\n",
    "borders.to_crs(epsg).plot(ax=ax, alpha=0.5)\n",
    "\n",
    "# add tide gauges\n",
    "# gdf.to_crs(epsg).buffer(25000).plot(color=\"red\", ax=ax, label=\"NOAA gauges w 25km buffer\")\n",
    "\n",
    "# add cities with a population over 100,000\n",
    "cities_gdf.loc[out & (cities_gdf[\"population\"] > pop_minimum), :].to_crs(epsg).plot(\n",
    "    color='green', \n",
    "    ax=ax, \n",
    "    label=\"cities w pop>100k within 5km of gauges\",\n",
    ")\n",
    "\n",
    "# plot\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb69ac-ccfb-4598-8c02-03dc28f8ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_minimum = 100000\n",
    "buffer_radius = 8000  # meters\n",
    "\n",
    "out = cities_gdf[cities_gdf[\"population\"] > pop_minimum].to_crs(epsg)[\"geometry\"].within(gdf.to_crs(epsg).buffer(buffer_radius).unary_union)\n",
    "print(f\"Cities within {buffer_radius/1000}km of a tide gauge: {np.sum(out)}\")\n",
    "cities_gdf.loc[out & (cities_gdf[\"population\"] > pop_minimum), [\"city\", \"state_id\"]].apply(lambda x: (x[\"city\"], x[\"state_id\"]), axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766cac4-2b1d-48ea-8599-073acabb0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# are the NYC stations in this dataset?\n",
    "# 8518750 (The Battery) and 8516945 (Kings Point)\n",
    "print(\"8518750\" in gdf.index)\n",
    "print(\"8516945\" in gdf.index)\n",
    "print(\"8519483\" in gdf.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67ef1fc-6e2d-4a03-b73f-8c36e810f9e9",
   "metadata": {},
   "source": [
    "# Temporal properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62410342-3ca8-418e-b005-d539b15e8ee2",
   "metadata": {},
   "source": [
    "## How continuous are the NaNs in the records?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d12c2-2139-4ce7-94ed-da00d81bea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_pickle(\"/data/surge/tide-gauge-hourly-records-eastcoast-sparse.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a7dd9b-6e07-49ee-8eaf-baf4a7fe2b78",
   "metadata": {},
   "source": [
    "### Pick an arbitrary record for testing\n",
    "`\"8518750\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ccbab9-089b-4a89-8bf3-bedc1098723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indices of the valid records\n",
    "valid_hours = [i for i, x in enumerate(merged_df[\"8518750\"][\"v\"].isna()) if not x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a78c07-d2f4-41b9-836c-0285691be382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index of first valid hour\n",
    "print(valid_hours[0])\n",
    "# create a series starting here\n",
    "series = merged_df[\"8518750\"].iloc[valid_hours[0]:valid_hours[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee41e2-58ba-4564-b691-4fc3c0982c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4b3267-fcd9-422a-b504-f11652982b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many NaNs remain\n",
    "np.sum(series[\"v\"].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ca9859-1401-4fd5-94d1-e725ccf99ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this feels like an interview problem\n",
    "invalid_hours = [i for i, x in enumerate(series[\"v\"].isna()) if x]\n",
    "invalid_hours[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c282e4-1256-4b98-8cbc-ac3fdca132f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_hours[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa7235a-bb33-4212-86d0-583344ca7e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b0e94d-98c4-43bd-8558-8161d1927d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "series.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d4b01-99ac-4d63-b554-2a0f72523de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "end = 0\n",
    "\n",
    "for i, x in enumerate(series[\"v\"].isna()):\n",
    "    if x:\n",
    "        # if we're at a NaN index, start counting\n",
    "        start = i\n",
    "        break\n",
    "\n",
    "# start at the NaN index, look for the point where it becomes valid\n",
    "for i, x in enumerate(series[\"v\"].iloc[start:].isna()):\n",
    "    if not x:\n",
    "        # when we reach a valid index, stop counting\n",
    "        end = (i + start)\n",
    "        break\n",
    "\n",
    "consecutive_nans = end - start\n",
    "print(consecutive_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bf914e-7bef-41e7-96b2-5a7584b56d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap previous cell into a function\n",
    "def consecutive_nans(series):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    running = True\n",
    "    nan_periods = []\n",
    "\n",
    "    while running:\n",
    "        for i, x in enumerate(series.iloc[start:].isna()):\n",
    "            if x:\n",
    "                # if we're at a NaN index, start counting\n",
    "                start = i\n",
    "                break\n",
    "        \n",
    "        # start at the NaN index, look for the point where it becomes valid\n",
    "        for i, x in enumerate(series.iloc[start:].isna()):\n",
    "            if not x:\n",
    "                # when we reach a valid index, stop counting\n",
    "                end = (i + start)\n",
    "                break\n",
    "\n",
    "        consecutive_nans = end - start\n",
    "        if consecutive_nans == 0:\n",
    "            break\n",
    "    \n",
    "        start = end\n",
    "        print(consecutive_nans)\n",
    "        nan_periods.append(consecutive_nans)\n",
    "        \n",
    "    return nan_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2278e868-2770-4fad-921c-947a8aba9b2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = consecutive_nans(series[\"v\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba963b1-9c5a-4822-bbbe-7f826d3ace7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691062ea-5d52-4111-8a5f-500eacfcf8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(start)\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f33d2-5408-452f-86b9-e05aaaeab578",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(series[\"v\"].iloc[56712:].isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e16b3-5bc7-4e55-8db8-219260922073",
   "metadata": {},
   "source": [
    "so there are still NaNs even after that big chunk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee58c4-3ad8-4f99-92b0-c0bc4a309048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this feels like an interview problem\n",
    "invalid_hours = [i for i, x in enumerate(series[\"v\"].iloc[51700:].isna()) if x]\n",
    "invalid_hours[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02abed8-0b63-4000-a190-adca5358ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/41968892/counting-consecutive-numbers-in-a-list\n",
    "def countlist(l):\n",
    "    count = 0\n",
    "    retlist = []\n",
    "    # Avoid IndexError for  random_list[i+1]\n",
    "    for i in range(len(l) - 1):\n",
    "        # Check if the next number is consecutive\n",
    "        if l[i] + 1 == l[i+1]:\n",
    "            count += 1\n",
    "        else:\n",
    "            # If it is not append the count and restart counting\n",
    "            retlist.append(count)\n",
    "            count = 1\n",
    "    # Since we stopped the loop one early append the last count\n",
    "    retlist.append(count)\n",
    "    return retlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21059f09-9c50-4489-bbbd-d16ff61c81b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counts of the number of consecutive NaNs\n",
    "out = countlist(invalid_hours)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4593c-f111-4486-b40f-9317ac2ea043",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(out)\n",
    "plt.xlabel(\"consecutive hours of missing data\")\n",
    "plt.ylabel('counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae7e51e-9069-4fb2-bb13-11391c2610ee",
   "metadata": {},
   "source": [
    "## Making this a little cleaner and more efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c2b27-ca08-4952-ac92-d8348c010c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the indices of the valid records\n",
    "series = merged_df[\"8518750\"][\"v\"]\n",
    "valid_hours = [i for i, x in enumerate(merged_df[\"8518750\"][\"v\"].isna()) if not x]\n",
    "\n",
    "# cut off any NaNs at the beginning or end\n",
    "series = series.iloc[valid_hours[0]:valid_hours[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc6e36-aa00-423b-ab95-d1a717c267d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_hours = [i for i, x in enumerate(series.isna()) if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07df685e-a6cb-495b-96c9-05f0fb6e2270",
   "metadata": {},
   "outputs": [],
   "source": [
    "consecutive_nans = countlist(invalid_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d96a3-f457-4c93-9465-94f718754341",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(consecutive_nans) / 24, bins=30)\n",
    "plt.xlabel(\"consecutive days of missing data\")\n",
    "plt.ylabel('counts')\n",
    "plt.title(f\"Gauge 8518750\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0d62c2-b9e8-4f1d-a8af-3b47a30f7921",
   "metadata": {},
   "source": [
    "## Repeating for all gauges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee5eba-33f4-419c-b172-460ad58e5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51b345-9796-4471-8ef2-3c1feed9c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = [x[0] for x in merged_df.columns.tolist()]\n",
    "stations = list(set(stations))\n",
    "consecutive_nan_dict = {}\n",
    "for station_id in tqdm(stations):\n",
    "    series = merged_df[station_id][\"v\"]\n",
    "    valid_hours = [i for i, x in enumerate(series.isna()) if not x]\n",
    "    \n",
    "    # cut off any NaNs at the beginning or end\n",
    "    series = series.iloc[valid_hours[0]:valid_hours[-1]]\n",
    "\n",
    "    # calculate hours with NaNs\n",
    "    invalid_hours = [i for i, x in enumerate(series.isna()) if x]\n",
    "\n",
    "    # count up consecutiveness\n",
    "    consecutive_nans = countlist(invalid_hours)\n",
    "    consecutive_nan_dict[station_id] = consecutive_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c678b7-4a2b-46b5-a637-7a95616329f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "consecutive_nan_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57922e0c-7fa1-4a56-b257-4b195b81ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save this dict to the /data drive somewhere. not sure if we will use it, but it's small to store and time-consuming to reproduce\n",
    "import pickle\n",
    "with open(\"/data/surge/consecutive-nans-for-tidegauges.pickle\", \"wb\") as f:\n",
    "    pickle.dump(consecutive_nan_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f2c8bf-b77b-435a-b4e3-1efd9d212f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nan_lengths = []\n",
    "for key, val in consecutive_nan_dict.items():\n",
    "    all_nan_lengths.extend(val)\n",
    "\n",
    "plt.hist(all_nan_lengths, bins=100, range=(0, 7500))\n",
    "plt.title(\"length of outages across all eastern US tide gauges\")\n",
    "plt.xlabel(\"hours\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fdc5e2-5de4-4ad6-87cc-c536a04bbc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(all_nan_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3287de-c691-4634-add8-927b35ce9a05",
   "metadata": {},
   "source": [
    "## Figure out what % of each gauge's history it has been operating successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c632eca5-6d33-4c11-a787-35945494256e",
   "metadata": {},
   "source": [
    "### Test with one gauge first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0068ccc2-4f2e-4f76-962a-41070c89c9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = \"8410140\"\n",
    "\n",
    "# clip record to operating period\n",
    "series = merged_df.loc[:, idx[id, \"v\"]]\n",
    "not_nans = np.argwhere(~np.array(series.isna().tolist()))\n",
    "start, end = not_nans[0], not_nans[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c647c3c-df05-474d-bfea-1921fe9353df",
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = start[0], end[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a84f5-08df-4b45-8b87-f24e270a66ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "series = series.iloc[start:end]\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1358929c-6f0b-4f99-97b3-da1fc3ef786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction_valid = np.sum(~np.array(series.isna().tolist())) / len(series)\n",
    "fraction_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ef013-4825-4729-9a26-705328023135",
   "metadata": {},
   "source": [
    "### Repeat for all gauges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60e7f6-ccf7-4212-9c25-b7c9f05f3011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stations = [x[0] for x in merged_df.columns.tolist()]\n",
    "stations = list(set(stations))\n",
    "\n",
    "valid_records = {}\n",
    "for station_id in tqdm(stations):\n",
    "    series = merged_df.loc[:, idx[station_id, \"v\"]]\n",
    "    not_nans = np.argwhere(~np.array(series.isna().tolist()))\n",
    "    start, end = not_nans[0], not_nans[-1]\n",
    "    start, end = start[0], end[0]\n",
    "    series = series.iloc[start:end]\n",
    "    fraction_valid = np.sum(~np.array(series.isna().tolist())) / len(series)\n",
    "    valid_records[station_id] = fraction_valid\n",
    "    print(fraction_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb376c23-5c06-4d52-9eb9-371edb5a1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a histogram of the valid length for each gauge\n",
    "fracs = []\n",
    "for key, val in valid_records.items():\n",
    "    fracs.append(val)\n",
    "\n",
    "plt.hist(fracs, bins=20)\n",
    "plt.xlabel(\"Fraction of record that is valid data\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Valid fraction of tide gauge records (variable record lengths)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9ea27c-bec2-418f-8ed7-c1f303bbd7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e42ae7-70c8-4115-8d8c-13aa62ee0d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1- 0.957410081230533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafefa4f-f133-4ba8-8484-e85c387f855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save this history since it is quite time-consuming to generate\n",
    "import pickle\n",
    "with open(\"/data/surge/fraction-of-record-valid.pickle\", \"wb\") as f:\n",
    "    pickle.dump(fracs, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8557b3-ae61-41b2-98d8-c1e9a49790cb",
   "metadata": {},
   "source": [
    "## How easily can we detect surge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96193d0-3b8f-4dcf-b88b-3d17a34353b6",
   "metadata": {},
   "source": [
    "### Attempt a simple quantile approach on a single gauge first\n",
    "Get the 95th percentile of the gauge height (MSL). Find areas in the record where the gauge's height exceedes this level. Plot some time before and after.\n",
    "\n",
    "NB: ideally we may want to detrend sea level rise before doing this, or else calculate quantiles on a rolling basis. The 95% of gauge height will be very different in 1920 vs 2020 since sea level has risen about 30 cm! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d62ca-4485-4aed-8e42-d26681ddd984",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id = \"8410140\"\n",
    "series = merged_df.loc[:, idx[station_id, \"v\"]]\n",
    "# get a list of the valid values\n",
    "series_dropnans = series.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4d41a-d0a2-48d3-8a19-db9c85a37203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 99% quantile\n",
    "high_level = series_dropnans.quantile(0.999)\n",
    "print(high_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213e845-92c1-4a04-9cac-80dde5224a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "series[(series > high_level) & ~series.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01486335-fc81-4895-92fb-88ff348dfb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16,6))\n",
    "series.loc[\"2023-01-20\":\"2023-01-26\"].plot(ax=ax)\n",
    "ax.hlines(y=high_level, xmin=\"2023-01-20\", xmax=\"2023-01-27\", color=\"gray\", linestyle=\"dashed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d55f8-7bf7-4210-bfc3-46d74d83ca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest ever level\n",
    "np.max(series_dropnans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a553d7-45df-4b6c-a7e8-0745563e3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "series[(series > 4.35) & ~series.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd11a7-d705-4c82-8cbe-e856a2f8417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16,6))\n",
    "series.loc[\"2020-04-05\":\"2020-04-15\"].plot(ax=ax, label=\"water level\")\n",
    "ax.hlines(y=4.35, xmin=\"2020-04-05\", xmax=\"2020-04-16\", color=\"gray\", linestyle=\"dashed\", label=\"highest recorded value\")\n",
    "ax.set_title(f\"Water level in Eastport, ME (gauge {station_id})\")\n",
    "ax.set_ylabel(\"Hourly water level\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a5d50f-4512-4228-8f00-2fc37381d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any record of flooding or storms during that date?\n",
    "# get the station name\n",
    "noaa_coops.Station(station_id).name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d8067-e84a-451b-9a5d-75ffbf5dfb08",
   "metadata": {},
   "source": [
    "Nothing obvious in the news about coastal flooding during this period..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
